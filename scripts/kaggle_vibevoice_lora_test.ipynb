{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# VibeVoice 7B + LoRA (Private) — Kaggle Notebook\n",
        "\n",
        "Før du kjører:\n",
        "- Slå på GPU (T4/P100) og gjerne High-RAM\n",
        "- Slå på Internet: On (for å hente base-modellen fra Hugging Face)\n",
        "- Visibility: Private\n",
        "- Last opp to private Kaggle Datasets:\n",
        "  - LoRA-checkpoint: innholdet fra `checkpoint-3800/`\n",
        "  - VibeVoice-lib: innholdet fra `vendor/vibevoice/` (så `pyproject.toml` ligger i rot)\n",
        "\n",
        "Tips: Etter “Add Data” i Kaggle, se mappene under `/kaggle/input/` for nøyaktige katalognavn.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "pip -q install -U pip\n",
        "pip -q install \"transformers>=4.51.3\" accelerate \"peft>=0.11.0\" sentencepiece librosa soundfile torchaudio speechbrain numpy scipy tqdm pyyaml\n",
        "\n",
        "# Installer VibeVoice fra ditt private dataset (erstatt katalognavn om nødvendig)\n",
        "# Eksempel: /kaggle/input/vibevoice-lib\n",
        "if [ -d \"/kaggle/input/vibevoice-lib\" ]; then\n",
        "  pip -q install /kaggle/input/vibevoice-lib\n",
        "else\n",
        "  echo \"⚠️ Sett riktig katalognavn for VibeVoice-lib under /kaggle/input/\"\n",
        "fi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, glob, json, textwrap\n",
        "from pprint import pprint\n",
        "\n",
        "print(\"/kaggle/input contents:\")\n",
        "for p in sorted(glob.glob('/kaggle/input/*')):\n",
        "    print(\"-\", p)\n",
        "\n",
        "# Konfigurer dataset-stier (BYTT navn hvis nødvendig)\n",
        "LORA_DIR = \"/kaggle/input/vibevoice-lora-checkpoint\"  # <- endre hvis katalognavn er annet\n",
        "VIBEVOICE_LIB_DIR = \"/kaggle/input/vibevoice-lib\"      # <- endre hvis katalognavn er annet\n",
        "\n",
        "assert os.path.isdir(VIBEVOICE_LIB_DIR), \"VibeVoice-lib dataset ikke funnet. Endre VIBEVOICE_LIB_DIR.\"\n",
        "assert os.path.isdir(LORA_DIR), \"LoRA-checkpoint dataset ikke funnet. Endre LORA_DIR.\"\n",
        "\n",
        "print(\"OK: Dataset-stier ser gyldige ut.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from peft import PeftModel\n",
        "from vibevoice.modular.modeling_vibevoice_inference import VibeVoiceForConditionalGenerationInference\n",
        "\n",
        "BASE_MODEL_ID = \"Jmica/VibeVoice7B\"  # Hentes fra Hugging Face (Internet: On)\n",
        "\n",
        "device_map = \"auto\"  # shard mellom GPU/CPU ved behov (tåler 16GB GPU)\n",
        "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
        "\n",
        "print(\"Laster basemodell …\")\n",
        "model = VibeVoiceForConditionalGenerationInference.from_pretrained(\n",
        "    BASE_MODEL_ID,\n",
        "    torch_dtype=torch_dtype,\n",
        "    device_map=device_map,\n",
        "    low_cpu_mem_usage=True,\n",
        ")\n",
        "print(\"Påfører LoRA-adapter …\")\n",
        "model = PeftModel.from_pretrained(model, LORA_DIR)\n",
        "try:\n",
        "    model = model.merge_and_unload()\n",
        "except Exception:\n",
        "    pass\n",
        "model.eval()\n",
        "print(\"Dry-run OK: base + LoRA lastet.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Valgfritt: kort generering (kan feile pga minne). Kjør bare hvis dry-run var OK.\n",
        "import numpy as np, soundfile as sf\n",
        "from vibevoice.processor.vibevoice_processor import VibeVoiceProcessor\n",
        "\n",
        "TARGET_SR = 24000\n",
        "VISION_START, VISION_PAD, VISION_END = \"<|vision_start|>\", \"<|vision_pad|>\", \"<|vision_end|>\"\n",
        "\n",
        "def build_prompt(text: str, seconds: float) -> str:\n",
        "    approx_samples = int(seconds * TARGET_SR)\n",
        "    N = int(np.ceil(approx_samples / 3200))\n",
        "    control = \"[voice: neutral, non-identifiable, Norwegian bokmål]\"\n",
        "    return (\n",
        "        \"Text input:\\n\"\n",
        "        f\"Speaker: {text} {control}\\n\"\n",
        "        \"Speech output:\\n\"\n",
        "        f\"{VISION_START} \" + (\" \".join([VISION_PAD]*N) + \" \" if N>0 else \"\") + f\"{VISION_END}\\n\"\n",
        "    )\n",
        "\n",
        "seconds = 1.5\n",
        "text = \"Hei, dette er en veldig kort test.\"\n",
        "\n",
        "processor = VibeVoiceProcessor.from_pretrained(BASE_MODEL_ID)\n",
        "tok = processor.tokenizer\n",
        "tok.add_special_tokens({\"additional_special_tokens\":[VISION_START, VISION_PAD, VISION_END]})\n",
        "try:\n",
        "    model.resize_token_embeddings(len(tok))\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "prompt = build_prompt(text, seconds)\n",
        "inputs = tok([prompt], return_tensors=\"pt\")\n",
        "\n",
        "speech_input_mask = torch.zeros((1, inputs[\"input_ids\"].shape[1]), dtype=torch.bool)\n",
        "speech_masks = torch.zeros((1, 1), dtype=torch.bool)\n",
        "speech_tensors = torch.zeros((1, max(1, int(TARGET_SR*min(seconds,0.1)))), dtype=torch.float32)\n",
        "\n",
        "with torch.no_grad():\n",
        "    out = model.generate(\n",
        "        input_ids=inputs[\"input_ids\"],\n",
        "        attention_mask=inputs.get(\"attention_mask\"),\n",
        "        tokenizer=tok,\n",
        "        max_new_tokens=1,\n",
        "        show_progress_bar=False,\n",
        "        return_speech=True,\n",
        "        speech_tensors=speech_tensors,\n",
        "        speech_masks=speech_masks,\n",
        "        speech_input_mask=speech_input_mask,\n",
        "    )\n",
        "\n",
        "audio = None\n",
        "if hasattr(out, \"speech_outputs\") and out.speech_outputs:\n",
        "    audio = out.speech_outputs[0]\n",
        "if audio is None:\n",
        "    audio = np.zeros(int(seconds*TARGET_SR), dtype=np.float32)\n",
        "\n",
        "audio = np.squeeze(np.array(audio, dtype=np.float32))\n",
        "sf.write(\"/kaggle/working/out.wav\", audio, TARGET_SR)\n",
        "print(\"Lagret /kaggle/working/out.wav\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
